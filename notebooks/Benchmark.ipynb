{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark of various outlier detection models\n",
    "\n",
    "**[PyOD](https://github.com/yzhao062/Pyod)** is a comprehensive **Python toolkit** to **identify outlying objects** in \n",
    "multivariate data with both unsupervised and supervised approaches.\n",
    "\n",
    "The following models are used for comparison:\n",
    "\n",
    "  1. Linear Models for Outlier Detection:\n",
    "     1. **PCA: Principal Component Analysis** use the sum of\n",
    "       weighted projected distances to the eigenvector hyperplane \n",
    "       as the outlier outlier scores) [10]\n",
    "     2. **MCD: Minimum Covariance Determinant** (use the mahalanobis distances \n",
    "       as the outlier scores) [11, 12]\n",
    "     3. **One-Class Support Vector Machines** [3]\n",
    "     \n",
    "  2. Proximity-Based Outlier Detection Models:\n",
    "     1. **LOF: Local Outlier Factor** [1]\n",
    "     2. **kNN: k Nearest Neighbors** (use the distance to the kth nearest \n",
    "     neighbor as the outlier score)\n",
    "     3. **Average kNN** Outlier Detection (use the average distance to k \n",
    "     nearest neighbors as the outlier score)\n",
    "     4. **Median kNN** Outlier Detection (use the median distance to k nearest \n",
    "     neighbors as the outlier score)\n",
    "     5. **HBOS: Histogram-based Outlier Score** [5]\n",
    "     \n",
    "  3. Probabilistic Models for Outlier Detection:\n",
    "     1. **ABOD: Angle-Based Outlier Detection** [7]\n",
    "     2. **FastABOD: Fast Angle-Based Outlier Detection using approximation** [7]\n",
    "  \n",
    "  4. Outlier Ensembles and Combination Frameworks\n",
    "     1. **Isolation Forest** [2]\n",
    "     2. **Feature Bagging** [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... Processing arrhythmia.mat ...\n",
      "['arrhythmia', 452, 274, 14.6018]\n",
      "Angle-based Outlier Detector (ABOD) ROC:0.7687, precision @ rank n:0.3571\n",
      "Feature Bagging ROC:0.7806, precision @ rank n:0.4643\n",
      "Histogram-base Outlier Detection (HBOS) ROC:0.8511, precision @ rank n:0.5714\n",
      "Isolation Forest ROC:0.8499, precision @ rank n:0.5714\n",
      "K Nearest Neighbors (KNN) ROC:0.782, precision @ rank n:0.5\n",
      "Local Outlier Factor (LOF) ROC:0.7787, precision @ rank n:0.4643\n",
      "Minimum Covariance Determinant (MCD) ROC:0.8228, precision @ rank n:0.4286\n",
      "One-class SVM (OCSVM) ROC:0.7986, precision @ rank n:0.5\n",
      "Principal Component Analysis (PCA) ROC:0.7997, precision @ rank n:0.5\n",
      "\n",
      "... Processing cardio.mat ...\n",
      "['cardio', 1831, 21, 9.6122]\n",
      "Angle-based Outlier Detector (ABOD) ROC:0.6618, precision @ rank n:0.2571\n",
      "Feature Bagging ROC:0.6281, precision @ rank n:0.1\n",
      "Histogram-base Outlier Detection (HBOS) ROC:0.8755, precision @ rank n:0.4286\n",
      "Isolation Forest ROC:0.9437, precision @ rank n:0.5429\n",
      "K Nearest Neighbors (KNN) ROC:0.7665, precision @ rank n:0.3571\n",
      "Local Outlier Factor (LOF) ROC:0.6044, precision @ rank n:0.0714\n",
      "Minimum Covariance Determinant (MCD) ROC:0.8694, precision @ rank n:0.4857\n",
      "One-class SVM (OCSVM) ROC:0.9327, precision @ rank n:0.5\n",
      "Principal Component Analysis (PCA) ROC:0.9488, precision @ rank n:0.5714\n",
      "\n",
      "... Processing glass.mat ...\n",
      "['glass', 214, 9, 4.2056]\n",
      "Angle-based Outlier Detector (ABOD) ROC:0.755, precision @ rank n:0.3333\n",
      "Feature Bagging ROC:0.8514, precision @ rank n:0.3333\n",
      "Histogram-base Outlier Detection (HBOS) ROC:0.7068, precision @ rank n:0.0\n",
      "Isolation Forest ROC:0.6827, precision @ rank n:0.0\n",
      "K Nearest Neighbors (KNN) ROC:0.8394, precision @ rank n:0.3333\n",
      "Local Outlier Factor (LOF) ROC:0.8153, precision @ rank n:0.3333\n",
      "Minimum Covariance Determinant (MCD) ROC:0.7912, precision @ rank n:0.0\n",
      "One-class SVM (OCSVM) ROC:0.5703, precision @ rank n:0.3333\n",
      "Principal Component Analysis (PCA) ROC:0.6265, precision @ rank n:0.3333\n",
      "\n",
      "... Processing ionosphere.mat ...\n",
      "['ionosphere', 351, 33, 35.8974]\n",
      "Angle-based Outlier Detector (ABOD) ROC:0.9275, precision @ rank n:0.8364\n",
      "Feature Bagging ROC:0.9228, precision @ rank n:0.7818\n",
      "Histogram-base Outlier Detection (HBOS) ROC:0.6025, precision @ rank n:0.3818\n",
      "Isolation Forest ROC:0.8655, precision @ rank n:0.7091\n",
      "K Nearest Neighbors (KNN) ROC:0.9245, precision @ rank n:0.8545\n",
      "Local Outlier Factor (LOF) ROC:0.9279, precision @ rank n:0.7818\n",
      "Minimum Covariance Determinant (MCD) ROC:0.9459, precision @ rank n:0.8545\n",
      "One-class SVM (OCSVM) ROC:0.8353, precision @ rank n:0.7091\n",
      "Principal Component Analysis (PCA) ROC:0.7926, precision @ rank n:0.6364\n",
      "\n",
      "... Processing letter.mat ...\n",
      "['letter', 1600, 32, 6.25]\n",
      "Angle-based Outlier Detector (ABOD) ROC:0.8871, precision @ rank n:0.4091\n",
      "Feature Bagging ROC:0.8956, precision @ rank n:0.5227\n",
      "Histogram-base Outlier Detection (HBOS) ROC:0.6115, precision @ rank n:0.1136\n",
      "Isolation Forest ROC:0.6446, precision @ rank n:0.1591\n",
      "K Nearest Neighbors (KNN) ROC:0.8859, precision @ rank n:0.4318\n",
      "Local Outlier Factor (LOF) ROC:0.8832, precision @ rank n:0.4773\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-5927e0a3282e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\Desktop\\Pyod\\pyod\\models\\mcd.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                    \u001b[0msupport_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                    random_state=self.random_state)\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Use mahalanabis distance as the outlier score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\robust_covariance.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mcov_computation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nonrobust_covariance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             random_state=random_state)\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massume_centered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[0mraw_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\robust_covariance.py\u001b[0m in \u001b[0;36mfast_mcd\u001b[1;34m(X, support_fraction, cov_computation_method, random_state)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mselect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_best_sub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mcov_computation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov_computation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 random_state=random_state)\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0msubset_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_best_sub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_best_sub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[0mall_best_locations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubset_slice\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_locations_sub\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\robust_covariance.py\u001b[0m in \u001b[0;36mselect_candidates\u001b[1;34m(X, n_support, n_trials, select, n_iter, verbose, cov_computation_method, random_state)\u001b[0m\n\u001b[0;32m    278\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_support\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                     \u001b[0mcov_computation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov_computation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                     random_state=random_state))\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m# perform computations from every given initial estimates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\robust_covariance.py\u001b[0m in \u001b[0;36m_c_step\u001b[1;34m(X, n_support, random_state, remaining_iterations, initial_estimates, verbose, cov_computation_method)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mprevious_support\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msupport\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# compute a new support from the full data set mahalanobis distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinvh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[0mX_centered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_centered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX_centered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py\u001b[0m in \u001b[0;36mpinvh\u001b[1;34m(a, cond, rcond, lower, return_rank, check_finite)\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m     \u001b[1;31m# For Hermitian matrices, singular values equal abs(eigenvalues)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     \u001b[0mabove_cutoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcond\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m     \u001b[0mpsigma_diag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mabove_cutoff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabove_cutoff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2271\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[1;32m-> 2272\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   2273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhao066\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define data file and read X and y\n",
    "mat_file_list = ['arrhythmia.mat',\n",
    "                 'cardio.mat',\n",
    "                 'glass.mat',\n",
    "                 'ionosphere.mat',\n",
    "                 'letter.mat',\n",
    "                 'lympho.mat',\n",
    "                 'mnist.mat',\n",
    "                 'musk.mat',\n",
    "                 'optdigits.mat',\n",
    "                 'pendigits.mat',\n",
    "                 'pima.mat',\n",
    "                 'satellite.mat',\n",
    "                 'satimage-2.mat',\n",
    "                 'shuttle.mat',\n",
    "                 'vertebral.mat',\n",
    "                 'vowels.mat',\n",
    "                 'wbc.mat']\n",
    "\n",
    "# Define nine outlier detection tools to be compared\n",
    "random_state = np.random.RandomState(42)\n",
    "\n",
    "df_columns = ['Data', '#Samples', '# Dimensions', 'Outlier Perc', \n",
    "              'ABOD', 'FB', 'HBOS', 'IForest', 'KNN', 'LOF', 'MCD', 'OCSVM', 'PCA']\n",
    "result_df = pd.DataFrame(columns = df_columns)\n",
    "\n",
    "for mat_file in mat_file_list:\n",
    "    print(\"\\n... Processing\", mat_file, '...')\n",
    "    mat = loadmat(os.path.join('data', mat_file))\n",
    "\n",
    "    X = mat['X']\n",
    "    y = mat['y'].ravel()\n",
    "    outliers_fraction  = np.count_nonzero(y)/len(y)\n",
    "    outliers_percentage = round(outliers_fraction*100, ndigits=4)\n",
    "    result_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]\n",
    "    print(result_list)\n",
    "    \n",
    "    # 60% data for training and 40% for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=random_state)\n",
    "\n",
    "    # standardizing data for processing\n",
    "    X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "    \n",
    "    classifiers = {'Angle-based Outlier Detector (ABOD)': ABOD(\n",
    "        contamination=outliers_fraction),\n",
    "        'Feature Bagging': FeatureBagging(\n",
    "            contamination=outliers_fraction,\n",
    "            random_state=random_state),\n",
    "        'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
    "            contamination=outliers_fraction),\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                    random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(\n",
    "            contamination=outliers_fraction),\n",
    "        'Local Outlier Factor (LOF)': LOF(\n",
    "            contamination=outliers_fraction),\n",
    "        'Minimum Covariance Determinant (MCD)': MCD(\n",
    "            contamination=outliers_fraction),\n",
    "        'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),\n",
    "        'Principal Component Analysis (PCA)': PCA(\n",
    "            contamination=outliers_fraction),\n",
    "    }\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train_norm)\n",
    "        test_scores = clf.decision_function(X_test_norm)\n",
    "        \n",
    "        roc = np.round(roc_auc_score(y_test, test_scores), decimals=4)\n",
    "        prn = np.round(precision_n_scores(y_test, test_scores), decimals=4)\n",
    "        \n",
    "        print('{clf_name} ROC:{roc}, precision @ rank n:{prn}'.format(\n",
    "            clf_name=clf_name, roc=roc,prn=prn))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (226, 30) (226,)\n",
      "Test data: (152, 30) (152,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\", X_train.shape, y_train.shape)\n",
    "print(\"Test data:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing 20 kNN detectors\n",
      "Base detector 0 is fitted for prediction\n",
      "Base detector 1 is fitted for prediction\n",
      "Base detector 2 is fitted for prediction\n",
      "Base detector 3 is fitted for prediction\n",
      "Base detector 4 is fitted for prediction\n",
      "Base detector 5 is fitted for prediction\n",
      "Base detector 6 is fitted for prediction\n",
      "Base detector 7 is fitted for prediction\n",
      "Base detector 8 is fitted for prediction\n",
      "Base detector 9 is fitted for prediction\n",
      "Base detector 10 is fitted for prediction\n",
      "Base detector 11 is fitted for prediction\n",
      "Base detector 12 is fitted for prediction\n",
      "Base detector 13 is fitted for prediction\n",
      "Base detector 14 is fitted for prediction\n",
      "Base detector 15 is fitted for prediction\n",
      "Base detector 16 is fitted for prediction\n",
      "Base detector 17 is fitted for prediction\n",
      "Base detector 18 is fitted for prediction\n",
      "Base detector 19 is fitted for prediction\n"
     ]
    }
   ],
   "source": [
    "n_clf = 20  # number of base detectors\n",
    "\n",
    "# Initialize 20 base detectors for combination\n",
    "k_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140,\n",
    "          150, 160, 170, 180, 190, 200]\n",
    "\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([X_test.shape[0], n_clf])\n",
    "\n",
    "print('Initializing {n_clf} kNN detectors'.format(n_clf=n_clf))\n",
    "\n",
    "for i in range(n_clf):\n",
    "    k = k_list[i]\n",
    "\n",
    "    clf = KNN(n_neighbors=k, method='largest')\n",
    "    clf.fit(X_train_norm)\n",
    "\n",
    "    train_scores[:, i] = clf.decision_scores_\n",
    "    test_scores[:, i] = clf.decision_function(X_test_norm)\n",
    "    print('Base detector %i is fitted for prediction' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision score matrix on training data (226, 20)\n",
      "Decision score matrix on test data (152, 20)\n"
     ]
    }
   ],
   "source": [
    "# Decision scores have to be normalized before combination\n",
    "train_scores_norm, test_scores_norm = standardizer(train_scores,\n",
    "                                                   test_scores)\n",
    "\n",
    "# Predicted scores from all base detectors on the test data is \n",
    "# stored in train_scores_norm and test_scores_norm\n",
    "print('Decision score matrix on training data', train_scores_norm.shape)\n",
    "print('Decision score matrix on test data', test_scores_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
